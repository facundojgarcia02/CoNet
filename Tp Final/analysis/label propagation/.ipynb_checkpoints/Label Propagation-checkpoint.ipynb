{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import pickle\n",
    "\n",
    "from random import sample, seed\n",
    "from tqdm import tqdm\n",
    "from utils.propagators.directed import PropagateDirected\n",
    "from utils.metrics import accuracy\n",
    "\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Graph.\n",
    "G = nx.read_gexf(\"../../state_files/PyPi Network V4.gexf\")\n",
    "# Keep only giant component.\n",
    "gc_nodes = sorted(nx.connected_components(G.to_undirected()), key = lambda x: len(x), reverse=True)[0]\n",
    "not_gc_nodes = set(G.nodes()) - gc_nodes\n",
    "G.remove_nodes_from(not_gc_nodes)\n",
    "\n",
    "# Load labels.\n",
    "with open(\"../../state_files/PyPi Dataframe V4.pickle\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "labels = df[\"Topic\"].dropna().to_dict()\n",
    "# Remove 'Other' topic.\n",
    "for n, l in labels.items():\n",
    "    if 'Other/Nonlisted Topic' in l:\n",
    "        l.remove('Other/Nonlisted Topic')\n",
    "# Filter nodes with no topics.\n",
    "labels = dict(filter(lambda x: len(x[1]) > 0, labels.items()))\n",
    "# Keep nodes from giant component.\n",
    "labels = dict(filter(lambda x: x[0] in gc_nodes, labels.items()))\n",
    "\n",
    "# Split train and test set.\n",
    "test_size = 0.1\n",
    "\n",
    "test_nodes = sample(list(labels.keys()), int(test_size*len(labels.keys())))\n",
    "train_nodes = list(filter(lambda x: x not in test_nodes, labels.keys()))\n",
    "\n",
    "train_labels = dict(filter(lambda x: x[0] in train_nodes, labels.items()))\n",
    "test_labels = dict(filter(lambda x: x[0] in test_nodes, labels.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 54335/54335 [25:15<00:00, 35.86it/s]\n",
      "  1%|█▏                                                                            | 1426/96960 [00:32<31:57, 49.83it/s]"
     ]
    }
   ],
   "source": [
    "pl = PropagateDirected(G, train_labels, method = \"global\")\n",
    "final_labels = pl.propagate_all()\n",
    "acc = accuracy(test_labels, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_collector = []\n",
    "for n, l in train_labels.items():\n",
    "    label_collector += l\n",
    "\n",
    "# Pesos globales -> El peso para elegir cada tópico va a ser peso local / peso global.\n",
    "# Esto debería calcularlo el Propagador en su clase Padre.\n",
    "train_fracs = {t: v/len(label_collector) for t, v in Counter(label_collector).items()}\n",
    "train_fracs = dict(sorted(train_fracs.items(), key = lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_accuracy(test_labels: dict, pred_labels: dict) -> float:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get topics and percentage of each in test set.\n",
    "    label_collector = []\n",
    "    for n, l in test_labels.items():\n",
    "        label_collector += l\n",
    "\n",
    "    topics = set(label_collector)\n",
    "    test_fracs = {t: v/len(label_collector) for t, v in Counter(label_collector).items()}\n",
    "    test_fracs = dict(sorted(test_fracs.items(), key = lambda x: x[1], reverse=True))\n",
    "    \n",
    "    # Init dicts.\n",
    "    times_seen = {t: 0 for t in topics}\n",
    "    matches = {t: 0 for t in topics}\n",
    "    \n",
    "    # Find nodes that were predicted.\n",
    "    found_test_labels = {n: l for n, l in test_labels.items() if n in pred_labels.keys()}\n",
    "\n",
    "    for n, l in found_test_labels.items():\n",
    "        if not isinstance(l, list):\n",
    "            raise Exception(\"No debería de haber etiquetas de testeo que no sean listas.\")          \n",
    "\n",
    "        # Revisamos que la la etiqueta encontrada esté en la lista de las de testeo.\n",
    "        if isinstance(pred_labels[n], str):\n",
    "            for _l in l:\n",
    "                times_seen[_l] += 1\n",
    "            if pred_labels[n] in l: \n",
    "                matches[pred_labels[n]] += 1\n",
    "\n",
    "        # En caso de que sea una lista la encontrada, nos fijamos que haya una coincidencia por lo menos.\n",
    "        elif isinstance(pred_labels[n], list):\n",
    "            for _l in l:\n",
    "                times_seen[_l] += 1\n",
    "            if pred_labels[n] in l: \n",
    "                matches[pred_labels[n]] += 1\n",
    "\n",
    "        #No debería de haber etiquetas propagadas que no sean str o list.\n",
    "        else:\n",
    "            raise Exception(\"No debería de haber etiquetas finales que no sean lista o str.\")\n",
    "    \n",
    "    accuracy_per_topic = {t: matches[t]/times_seen[t] for t in topics}\n",
    "    bal_acc = sum(accuracy_per_topic.values())/len(accuracy_per_topic.values())\n",
    "    return bal_acc, times_seen\n",
    "    \n",
    "acc_x_t, ts = balanced_accuracy(test_labels, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: Modelo de propagación aleatoria.\n",
      "13%\n",
      "Balanced Accuracy: Modelo de tirar un dado de 23 caras\n",
      "3%\n",
      "Balanced Accuracy: Modelo de etiquetar TODO con la etiqueta mas común\n",
      "2%\n"
     ]
    }
   ],
   "source": [
    "print(\"Balanced Accuracy: Modelo de propagación aleatoria.\")\n",
    "print(f\"{acc_x_t*100:.0f}%\")\n",
    "\n",
    "print(\"Balanced Accuracy: Modelo de tirar un dado de 23 caras\")\n",
    "label_collector = []\n",
    "for n, l in test_labels.items():\n",
    "    label_collector += l\n",
    "\n",
    "topics = set(label_collector)\n",
    "matches = {t: int(ts[t]/len(ts)) for t in topics}\n",
    "accuracy_per_topic = {t: matches[t]/ts[t] for t in topics}\n",
    "print(f\"{sum(accuracy_per_topic.values())/len(accuracy_per_topic.values())*100:.0f}%\")\n",
    "\n",
    "print(\"Balanced Accuracy: Modelo de etiquetar TODO con la etiqueta mas común\")\n",
    "print(f'{1 * (ts[\"Software Development\"]/sum(ts.values())) / len(ts)*100:.0f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a42cd95ca9a57c6387dbbfdd995a278478871c13a93fa5b980ac93bb6d23c0e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
